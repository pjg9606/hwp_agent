import os
import shutil
from dotenv import load_dotenv
from langchain_upstage import UpstageDocumentParseLoader
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document  
from langchain_community.vectorstores.utils import filter_complex_metadata

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# DBê°€ ì €ì¥ë  í´ë”ëª… (ë¡œì»¬ í´ë”ì— ì €ì¥ë¨)
CHROMA_PATH = "chroma_db"

def save_to_db(file_path):
    """
    1. HWP íŒŒì¼ì„ ì½ê³  (Load)
    2. ì ì ˆí•œ í¬ê¸°ë¡œ ìë¥´ê³  (Split)
    3. ë²¡í„° DBì— ì €ì¥í•©ë‹ˆë‹¤ (Embed & Store)
    """
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None

    # --- 1. Load (ë¬¸ì„œ ì½ê¸°) ---
    print(f"ğŸ“„ [Load] ë¬¸ì„œ ë¶„ì„ ì¤‘... ({file_path})")
    # ì˜µì…˜ì„ ë‹¤ ì§€ìš°ê³  íŒŒì¼ ê²½ë¡œì™€ split ì„¤ì •ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    loader = UpstageDocumentParseLoader(
        file_path,
        split="page"
    )
    docs = loader.load()

    # --- 2. Split (ë¬¸ì„œ ìª¼ê°œê¸°) ---
    print(f"âœ‚ï¸  [Split] ë¬¸ì„œ ë¶„í•  ì¤‘...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000,
        chunk_overlap=200,
    )
    chunks = text_splitter.split_documents(docs)
    
    # DBê°€ ì‹«ì–´í•˜ëŠ” ë³µì¡í•œ ë©”íƒ€ë°ì´í„°(ì¢Œí‘œê°’ ë“±)ë¥¼ ê±¸ëŸ¬ëƒ…ë‹ˆë‹¤.
    chunks = filter_complex_metadata(chunks)

    print(f"   ğŸ‘‰ ì´ {len(docs)}í˜ì´ì§€ë¥¼ {len(chunks)}ê°œì˜ ì¡°ê°(Chunk)ìœ¼ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")

    # --- 3. Embed & Store (ì €ì¥í•˜ê¸°) ---
    print("ğŸ’¾ [Save] ë°ì´í„°ë² ì´ìŠ¤(Chroma)ì— ì €ì¥ ì¤‘... (OpenAI ê³¼ê¸ˆ ë°œìƒ)")
    
    # â–¼â–¼â–¼ [ìˆ˜ì •ëœ ë¶€ë¶„] í´ë” ì‚­ì œ ëŒ€ì‹  ë°ì´í„° ì´ˆê¸°í™” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ â–¼â–¼â–¼
    
    # 1. DB ì—°ê²° (ì—†ìœ¼ë©´ ìƒì„±ë¨)
    db = Chroma(
        persist_directory=CHROMA_PATH,
        embedding_function=OpenAIEmbeddings(model="text-embedding-3-small")
    )
    
    # 2. ê¸°ì¡´ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì‚­ì œ (Reset)
    # Windows íŒŒì¼ ì ê¸ˆ(WinError 32)ì„ í”¼í•˜ê¸° ìœ„í•´ í´ë”ë¥¼ ì§€ìš°ì§€ ì•Šê³  ë‚´ìš©ë§Œ ë¹„ì›ë‹ˆë‹¤.
    existing_ids = db.get()['ids']
    if existing_ids:
        print(f"ğŸ§¹ ê¸°ì¡´ ë°ì´í„° {len(existing_ids)}ê°œë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
        db.delete(ids=existing_ids)
        
    # 3. ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€
    db.add_documents(chunks)

    
    print(f"âœ… ì €ì¥ ì™„ë£Œ! DB ê²½ë¡œ: ./{CHROMA_PATH}")
    return db

def query_db(query_text):
    """
    ì €ì¥ëœ DBì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ëœ ë‚´ìš©ì„ ì°¾ì•„ì˜µë‹ˆë‹¤.
    """
    # ì €ì¥ëœ DB ë¶ˆëŸ¬ì˜¤ê¸°
    db = Chroma(
        persist_directory=CHROMA_PATH, 
        embedding_function=OpenAIEmbeddings(model="text-embedding-3-small")
    )
    
    # ìœ ì‚¬ë„ ê²€ìƒ‰ (Similarity Search)
    results = db.similarity_search(query_text, k=3) # ìƒìœ„ 3ê°œ ê²°ê³¼
    return results

if __name__ == "__main__":
    # --- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---
    TEST_FILE = "sample.hwp"
    
    if os.path.exists(TEST_FILE):
        # 1. DB ìƒì„±
        save_to_db(TEST_FILE)
        
        # 2. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        test_query = "ì§€ì› ëŒ€ìƒ ë¶„ì•¼ê°€ ì–´ë””ì•¼?" 
        
        print(f"\nğŸ” [Query] ì§ˆë¬¸: '{test_query}'")
        results = query_db(test_query)
        
        print("\n--- [ê²€ìƒ‰ ê²°ê³¼] ---")  #Sanity Check(ê±´ì „ì„± ê²€ì‚¬)
        if results:
            for i, res in enumerate(results):
                print(f"[{i+1}] ...{res.page_content[:200]}...")
                print("--------------------------------------------------")
        else:
            print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"âš ï¸ '{TEST_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")